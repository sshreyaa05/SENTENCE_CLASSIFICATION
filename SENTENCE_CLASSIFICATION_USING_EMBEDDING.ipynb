{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**CREATING AN ARTIFICIAL NEURAL NETWORK (ANN) USING AN EMBEDDED LAYER TO CLASSIFY THE FOLLOWING REVIEWS FROM RESTRAUNT**\n",
        "\n",
        "'Never coming back!',\n",
        "\n",
        "'horrible service',\n",
        "\n",
        "'rude waitress',\n",
        "\n",
        "'cold food',\n",
        "\n",
        "'horrible food!',\n",
        "\n",
        "'awesome',\n",
        "\n",
        "'awesome services!',\n",
        "\n",
        "'rocks',\n",
        "\n",
        "'poor work',\n",
        "\n",
        "'couldn't have done better'\n",
        "\n",
        "Where the 1,2,3,4,5 and 9 are negative statements and the rest 6,7,8,and 10 are positive statements (0 for negative class and 1 for positive class).\n",
        "\n"
      ],
      "metadata": {
        "id": "1OZWIbJf6e73"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qv3cHubu4p6R"
      },
      "outputs": [],
      "source": [
        "## IMPORT NECESSARY LIBRARIES\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, Flatten\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from keras.metrics import BinaryAccuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## DEFINING THE DATA\n",
        "reviews = [\n",
        "'Never coming back!',\n",
        "\n",
        "'horrible service',\n",
        "\n",
        "'rude waitress',\n",
        "\n",
        "'cold food',\n",
        "\n",
        "'horrible food!',\n",
        "\n",
        "'awesome',\n",
        "\n",
        "'awesome services!',\n",
        "\n",
        "'rocks',\n",
        "\n",
        "'poor work',\n",
        "\n",
        "'couldn\\'t have done better'\n",
        " ]"
      ],
      "metadata": {
        "id": "unAXKvJO8f86"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## DATA PREPARATION USING TOKENIZATION AND ENCODING THE WORDS\n",
        "\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(reviews)\n",
        "\n",
        "encoded_docs = t.texts_to_sequences(reviews)\n",
        "encoded_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp865j7t6Y2j",
        "outputId": "cd57e646-93ba-4885-a0c1-2580dbacf042"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4, 5, 6],\n",
              " [1, 7],\n",
              " [8, 9],\n",
              " [10, 2],\n",
              " [1, 2],\n",
              " [3],\n",
              " [3, 11],\n",
              " [12],\n",
              " [13, 14],\n",
              " [15, 16, 17, 18]]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## CONVERTING THE ABOVE DATA SO THAT ALL THE ENCODED LISTS HAVE SAME NUMBER OF ELEMENTS\n",
        "max_length = 4\n",
        "padded_reviews = pad_sequences(encoded_docs, maxlen = max_length, padding = 'post')\n",
        "padded_reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qny6svac9Yb1",
        "outputId": "3a16a01a-301a-4df2-f360-97bed11a1c2c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4,  5,  6,  0],\n",
              "       [ 1,  7,  0,  0],\n",
              "       [ 8,  9,  0,  0],\n",
              "       [10,  2,  0,  0],\n",
              "       [ 1,  2,  0,  0],\n",
              "       [ 3,  0,  0,  0],\n",
              "       [ 3, 11,  0,  0],\n",
              "       [12,  0,  0,  0],\n",
              "       [13, 14,  0,  0],\n",
              "       [15, 16, 17, 18]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## DEFINING THE TARGET CLASSES\n",
        "y = array([0,0,0,0,0,1,1,1,0,1])"
      ],
      "metadata": {
        "id": "9pYxvoAU9ZYf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(t.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt4Fam4NBY1T",
        "outputId": "a8eec36a-a0a3-4174-89e3-fb3fb5eed757"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## CREATION OF ANN USING EMBEDDED LAYER\n",
        "model = Sequential()\n",
        "vocabulary_size = 19 # one added with the number of 18 unique terms in the corpus\n",
        "emb_layer = Embedding(input_dim = vocabulary_size, output_dim = 10, input_length = max_length)\n",
        "model.add(emb_layer)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(16, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YH73wl69ZU9",
        "outputId": "1eb7be0c-4e2f-46ae-c0a8-381f5d1e70af"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 4, 10)             190       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 40)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                656       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 863 (3.37 KB)\n",
            "Trainable params: 863 (3.37 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## MODEL COMPILATION\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['acc'])"
      ],
      "metadata": {
        "id": "aBou2DTx9ZTD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TRAINING THE NETWORK\n",
        "model.fit(padded_reviews, y, epochs = 10)"
      ],
      "metadata": {
        "id": "7mXRJMAm9ZQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75bcd0a9-b876-42ab-fcc7-794f0f677a8f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 633ms/step - loss: 0.6977 - acc: 0.3000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6941 - acc: 0.5000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6906 - acc: 0.5000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6870 - acc: 0.6000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6837 - acc: 0.6000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6809 - acc: 0.6000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6782 - acc: 0.7000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6758 - acc: 0.7000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6735 - acc: 0.7000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6712 - acc: 0.7000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fbcbc0ae680>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## INLINE PREDICTION AND EVALUATION\n",
        "y_pr = np.round(model.predict(padded_reviews))\n",
        "print(y_pr)"
      ],
      "metadata": {
        "id": "mMnapoWu9ZOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67d4f13b-f504-4c7c-837e-fa0236517949"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 84ms/step\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bac = BinaryAccuracy()\n",
        "accuracy = bac(y, model.predict(padded_reviews)).numpy()\n",
        "print('Binary Accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "PRRqFxP69ZMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1acb61c6-85f5-46b6-fc6b-9b8b6560eabe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "Binary Accuracy: 0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## OUTLINE PREDICTION (PREDICTING THE CLASS OF THE SENTENCE : 'cold horrible')\n",
        "test = array([[10, 1, 0, 0]])\n",
        "print(np.round(model.predict(test)))"
      ],
      "metadata": {
        "id": "vv-cYpL79ZKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "128b46c9-4432-404d-bc8b-1c0f8bc13ffc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 55ms/step\n",
            "[[0.]]\n"
          ]
        }
      ]
    }
  ]
}